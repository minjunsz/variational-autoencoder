{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, ModelSummary\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from data_modules import MNIST\n",
    "from models.naive_vae import NaiveVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate pl.Datamodule & pl.LightningModule\n",
    "\n",
    "Data dir should be consistent in order not to re-download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MNIST.MNISTDataModule(\"./downloads\")\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "vae = NaiveVAE(in_channels=1, hidden_dim=[8, 16, 32, 64], latent_dim=128, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fast_dev_run\n",
    "\n",
    "Thanks to pytorch-lightning's fast_dev_run mode, the model would be trained based on a single batch.  \n",
    "ModelSummary callback prints the dimension of the intermediate results, which is estimated according to the example input.\n",
    "The example input, `example_input_array`, is define in the model's `__init__` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug train\n",
    "trainer = pl.Trainer(\n",
    "    fast_dev_run=True,\n",
    "    callbacks=[ModelSummary(max_depth=1)],\n",
    ")\n",
    "trainer.fit(model=vae, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit on small batch\n",
    "\n",
    "In order to check whether the model is expressive enough, it'd be better to train on small batches. The model should overfit on them quickly.  \n",
    "Learning rate can be adjusted, by tracking gradients while overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"checkpoints/naive_vae\",\n",
    "    overfit_batches=10,\n",
    "    track_grad_norm=2,\n",
    "    max_epochs=500,\n",
    ")\n",
    "\n",
    "trainer.fit(model=vae, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(name='Adam-32-0.001',project='NaiveVAE', log_model='all')\n",
    "wandb_logger.watch(vae, log='all')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_total_loss\", mode=\"min\", save_top_k=2)\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"checkpoints/naive_vae\",\n",
    "    track_grad_norm=2,\n",
    "    max_epochs=2,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model=vae,datamodule=dm)\n",
    "wandb_logger.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WandbLogger.finalize() missing 1 required positional argument: 'status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/machine-learning/VAE/train_model.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f7079746f726368222c22637764223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74752d32302e30345c5c686f6d655c5c6d696e6a756e5c5c636f6465735c5c6d616368696e652d6c6561726e696e67227d/root/machine-learning/VAE/train_model.ipynb#ch0000015vscode-remote?line=0'>1</a>\u001b[0m wandb_logger\u001b[39m.\u001b[39;49mfinalize()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Any]:\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m rank_zero_only\u001b[39m.\u001b[39mrank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: WandbLogger.finalize() missing 1 required positional argument: 'status'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
